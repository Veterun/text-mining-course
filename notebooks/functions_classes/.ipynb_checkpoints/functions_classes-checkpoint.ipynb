{
 "metadata": {
  "name": "",
  "signature": "sha256:cf804c0bcf2ff43a59da7788cd9a693dbaad876869dc0381c49bfa45947629f6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Functions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To define a function in Python, we use def(var1,...,varN): followed by an indented codeblock that performs operations on the variables.  If we want the function to return a value, we use the return keyword."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def my_function(x,y):\n",
      "    z = x + y\n",
      "    return z"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We then call the function as follows"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print my_function(6,7)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that we didn't specify what types of variable x and y were.  Here we passed integers, and addition was performed.  If we had passed strings the function would have concatenated them."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print my_function('stephen',' hansen')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "stephen hansen\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Functions can also return multiple values of different types."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def my_function2(x,y):\n",
      "    z = x + y\n",
      "    return z, [x,y,z]\n",
      "\n",
      "r1,r2 = my_function2(6,7)\n",
      "print r1,r2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13 [6, 7, 13]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Functions can also take functions as arguments.  For example, the built-in map function takes as its first argument a function and further arguments that specify inputs, and returns a list of return values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print map(my_function,[1,2,3],[4,5,6])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[5, 7, 9]\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In some situations, we'd like to not have to explictly define a function to pass as an argument if it will never be used in other parts of the program.  Python has a special lambda operator that allows on-the-fly function definition for this purpose."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list_of_lists = [[1,2],[3,4,5],[10]]\n",
      "length_of_lists = map(len,list_of_lists)\n",
      "print length_of_lists\n",
      "\n",
      "length_of_lists_sq = map(lambda x: len(x)*len(x),list_of_lists)\n",
      "print length_of_lists_sq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[2, 3, 1]\n",
        "[4, 9, 1]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Functions are also objects, and can be stored in containers like lists."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def my_function2(x,y):\n",
      "    z = x + y\n",
      "    return 2*z\n",
      "\n",
      "my_funcs = [my_function,my_function2]\n",
      "print my_funcs[0](1,2)\n",
      "print my_funcs[1](1,2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3\n",
        "6\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, basically, a Python function is a far more flexible object than functions in many other languages."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The object oriented programming paradigm allows us to define new data types, and functions to apply to these data types, in a single entity (called an object) that we can then carry around in our programs.  This allows us to build an abstract template for operations that we can then call for as many specific applications as we want, which tends to make coding much clean and efficient.\n",
      "\n",
      "Whether you've realized it or not, we have been using object oriented programming already in performing operations on strings.  When we define a string variable we in fact are creating an object that comes with a set of functions we can apply to it, which are now called methods.  You can access all of an object's attributes, including its methods, with the dir function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "my_string = 'my_string'\n",
      "print dir(my_string)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['__add__', '__class__', '__contains__', '__delattr__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__getslice__', '__gt__', '__hash__', '__init__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '_formatter_field_name_split', '_formatter_parser', 'capitalize', 'center', 'count', 'decode', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'index', 'isalnum', 'isalpha', 'isdigit', 'islower', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'partition', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Of course, we'll want to create are own objects, so let's illustrate with text processing.  An object's attributes are defined within a class.  Let's start building up a class for text pre-processing as we saw in lecture."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import codecs,re\n",
      "from nltk.tokenize import wordpunct_tokenize\n",
      "from nltk import PorterStemmer\n",
      "\n",
      "class RawDocs():\n",
      "    \n",
      "\tdef __init__(self, doc_data, stopword_file):\n",
      "\n",
      "\t\tself.docs = [s.lower() for s in doc_data]\n",
      "\t\tself.docs = map(lambda x: re.sub(u'[\\u2019\\']', '', x), self.docs)\n",
      "\n",
      "\t\twith codecs.open(stopword_file,'r','utf-8') as f: raw = f.read()\n",
      "\t\tself.stopwords = set(raw.splitlines())\n",
      "\n",
      "\t\tself.N = len(self.docs)\n",
      "\t\tself.tokens = map(wordpunct_tokenize,self.docs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first element of the class definition is a call to \\_\\_init\\_\\_, whose first argument \"self\" is an object created with RawDocs.  The further arguments are data that are used to create attributes for self at its creation: in this case, an iterable containing strings and a path to a file containing stopwords.\n",
      "\n",
      "self is given four attributes on creation: a list of case-folded and apostrophe-stripped document strings (docs); a set of stopwords (stopwords); a number of documents (N); a list of lists containing tokenized documents (tokens).  They can be accessed with the dot operator.\n",
      "\n",
      "Let's illustrate this with real data on State of the Union Addresses."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "data = pd.read_table(\"speech_data_extend.txt\",encoding=\"utf-8\")\n",
      "print data.columns\n",
      "data = data[data.year >= 1947]\n",
      "print data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Index([u'president', u'speech', u'year'], dtype='object')\n",
        "(9488, 3)\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "docsobj = RawDocs(data.speech,'stopwords.txt')\n",
      "print docsobj.docs[0]\n",
      "print docsobj.tokens[0]\n",
      "print docsobj.stopwords\n",
      "print docsobj.N"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "mr. president, mr. speaker, members of the congress of the united states: \n",
        "[u'mr', u'.', u'president', u',', u'mr', u'.', u'speaker', u',', u'members', u'of', u'the', u'congress', u'of', u'the', u'united', u'states', u':']\n",
        "set([u'all', u'just', u'less', u'being', u'over', u'both', u'four', u'through', u'yourselves', u'go', u'still', u'its', u'before', u'now', u'also', u'herself', u'had', u'should', u'to', u'only', u'under', u'ours', u'has', u'ought', u'do', u'them', u'his', u'goes', u'get', u'very', u'every', u'whether', u'they', u'not', u'during', u'one', u'him', u'nor', u'like', u'did', u'this', u'she', u'each', u'further', u'where', u'few', u'because', u'says', u'doing', u'some', u'back', u'see', u'are', u'our', u'ourselves', u'out', u'even', u'what', u'said', u'for', u'since', u'while', u'does', u'above', u'between', u'new', u'ever', u'be', u'we', u'who', u'were', u'however', u'here', u'hers', u'by', u'on', u'about', u'would', u'of', u'could', u'against', u'or', u'first', u'own', u'into', u'yourself', u'down', u'put', u'least', u'another', u'old', u'your', u'second', u'long', u'from', u'her', u'their', u'there', u'two', u'been', u'whom', u'too', u'way', u'themselves', u'was', u'until', u'more', u'himself', u'that', u'but', u'with', u'than', u'those', u'he', u'me', u'myself', u'made', u'these', u'up', u'us', u'below', u'three', u'theirs', u'my', u'say', u'and', u'then', u'is', u'am', u'it', u'an', u'high', u'as', u'itself', u'at', u'have', u'in', u'seen', u'any', u'if', u'again', u'no', u'make', u'when', u'same', u'how', u'other', u'take', u'which', u'you', u'many', u'after', u'most', u'never', u'such', u'why', u'a', u'off', u'i', u'well', u'yours', u'so', u'five', u'the', u'having', u'once'])\n",
        "9488\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Of course, we generally want to write functions to apply to an object's attributes, or even create new attributes.  Let's extend our class in order to do basic text pre-processing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class RawDocs2():\n",
      "\n",
      "\tdef __init__(self, doc_data, stopword_file):\n",
      "\n",
      "\t\tself.docs = [s.lower() for s in doc_data]\n",
      "\n",
      "\t\twith codecs.open(stopword_file,'r','utf-8') as f: raw = f.read()\n",
      "\t\tself.stopwords = set(raw.splitlines())\n",
      "\n",
      "\t\tself.docs = map(lambda x: re.sub(u'[\\u2019\\']', '', x), self.docs)\n",
      "\n",
      "\t\tself.N = len(self.docs)\n",
      "\t\tself.tokens = map(wordpunct_tokenize,self.docs)\n",
      "\n",
      "\n",
      "\tdef token_clean(self,length):\n",
      "\n",
      "\t\t\"\"\" \n",
      "\t\tstrip out non-alpha tokens and length one tokens\n",
      "\t\t\"\"\"\n",
      "\n",
      "\t\tdef clean(tokens): return [t for t in tokens if t.isalpha() == 1 and len(t) > length]\n",
      "\n",
      "\t\tself.tokens = map(clean,self.tokens)\n",
      "\n",
      "\n",
      "\tdef stopword_remove(self):\n",
      "\n",
      "\t\t\"\"\"\n",
      "\t\tRemove stopwords from tokens.\n",
      "\t\t\"\"\"\n",
      "\n",
      "\t\tdef remove(tokens): return [t for t in tokens if t not in self.stopwords]\n",
      "\t\tself.tokens = map(remove,self.tokens)\n",
      "\n",
      "\n",
      "\tdef stem(self):\n",
      "\n",
      "\t\t\"\"\"\n",
      "\t\tStem tokens with Porter Stemmer.\n",
      "\t\t\"\"\"\n",
      "\n",
      "\t\tdef s(tokens): return [PorterStemmer().stem(t) for t in tokens]\n",
      "\t\tself.stems = map(s,self.tokens)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now our class contains what look much like functions.  The main difference is that now the def statements take as their first argument \"self\" which indicates that they will be applied to objects created within this class.  In the OOP context, these are called methods rather than functions, but otherwise basically work as functions.  An important difference though is that the attributes of self are available to methods in RawDocs2 without having to be explicitly passed as would be the case with a function.\n",
      "\n",
      "RawDocs2 has three methods, one for stripping out non-alpha tokens, one for removing stopwords, and one for stemming.  Let's illustrate how these work, and their effect on dimensionality reduction.  Again, methods are called on objects using the dot operator."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "docsobj = RawDocs2(data.speech,'stopwords.txt')\n",
      "\n",
      "###### step 1 ######\n",
      "\n",
      "all_terms = [t for d in docsobj.tokens for t in d]\n",
      "print \"# tokens = \", len(all_terms)\n",
      "print \"# unique tokens = \", len(set(all_terms))\n",
      "print \"\\n\"\n",
      "\n",
      "###### step 2 ######\n",
      "\n",
      "docsobj.token_clean(0)\n",
      "all_terms = [t for d in docsobj.tokens for t in d]\n",
      "print \"# alpha tokens = \", len(all_terms)\n",
      "print \"# unique alpha tokens = \", len(set(all_terms))\n",
      "print \"\\n\"\n",
      "\n",
      "###### step 3 ######\n",
      "\n",
      "docsobj.token_clean(1)\n",
      "docsobj.stopword_remove()\n",
      "all_terms = [t for d in docsobj.tokens for t in d]\n",
      "print \"# alpha tokens without stopwords = \", len(all_terms)\n",
      "print \"# unique alpha tokens without stopwords = \", len(set(all_terms))\n",
      "print \"\\n\"\n",
      "\n",
      "###### step 4 ######\n",
      "\n",
      "docsobj.stem()\n",
      "all_terms = [t for d in docsobj.stems for t in d]\n",
      "print \"# stems = \", len(all_terms)\n",
      "print \"# unique stems = \", len(set(all_terms))\n",
      "print '\\n'\n",
      "\n",
      "###### transformed first paragraph ######\n",
      "\n",
      "print docsobj.stems[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "# tokens =  591547\n",
        "# unique tokens =  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14914\n",
        "\n",
        "\n",
        "# alpha tokens = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 524449\n",
        "# unique alpha tokens =  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14354\n",
        "\n",
        "\n",
        "# alpha tokens without stopwords = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 267814\n",
        "# unique alpha tokens without stopwords =  14166\n",
        "\n",
        "\n",
        "# stems = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 267814\n",
        "# unique stems =  8287\n",
        "\n",
        "\n",
        "[u'mr', u'presid', u'mr', u'speaker', u'member', u'congress', u'unit', u'state']\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that all pre-processing is done in five lines (after importing the class).  Moreover, these same five lines can be used for any text data: the class provides a general template independent of any particular dataset.  This illustrates the usefulness of object oriented programming."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}
{
 "metadata": {
  "name": "",
  "signature": "sha256:7941d4855c4d8f68f6ef9a27f2e41d13e28146fe5e3c4a36303b98a2d7d8860e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Scraping Text Data from the Web"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The World Wide Web is a very rich source for text data of many kinds, but getting it might seem difficult at first.  The most na\u00efve approach to data collection from the web is to open a webpage in a browser, and copy and paste the text that appears.  This might be an efficient solution if all the data you want is on one or two webpages, but in general is wildly inefficient.  We want to find a way of automating, at least partially, data collection.  This is referred to as \"scraping\" a website.\n",
      "\n",
      "In this course, we will focus on scraping static HTML pages.  These are webpages written in HTML (Hyper-Text Markup Language) that appear the same for all users who access it.  For example, the webpages of UPF professors are static HTML pages.  Before proceeding, it's important to have some basic understanding of how HTML represents information."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "HTML"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "HTML provides web browsers text and other content that has been tagged with information on how it should be represented to viewers of the site.  The basic unit of HTML takes the form"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "<tagType attribute1 = \"value1\" attribute2 = \"value2\"> content </tagType>."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can take this is pieces.  First, tagType defines what the unit of text is supposed to represent.  For example, the \"a\" tag represents a link to another page; the \"p\" tag represents a paragraph; the \"td\" tage represents a cell in a table; and so on.  A complete list of tags is available from http://www.w3schools.com/tags/default.asp.  Second, tags can have one or more attributes (but can also have no attributes).  These provide information about the unit, such as its appearence, location, group membership, etc.  Different types of tag have different admissible attributes.  For example, the \"a\" tag has an \"href\" attribute whose value is a URL, and the \"p\" tag has an \"align\" attribute whose value determines the paragraph's alignment.  Finally, content is the content that will be displayed on the page.\n",
      "\n",
      "The structure of an HTML webpage is a nested set of tags.  In other words, content can contain other tags with the same structure as above.  For example, the \"td\" tag that defines a cell in a table is contained within the \"table\" tag, which itself might be contained in a \"div\" tag, which denotes a section in a document."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Getting HTML Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As a case study, we will collect data on the latest press releases from the Florida State Senate from https://www.flsenate.gov/Media/PressReleases/.  To view the HTML data, open the link on your web browser and choose its version of \"view source\", where you will see the HTML representation of the site.  Our task is to get the links from this page that represent press releases, open them, and get the text of the press release.\n",
      "\n",
      "The first step is to get the HTML data, which we can easily do with the requests module."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests\n",
      "response = requests.get('https://www.flsenate.gov/Media/PressReleases')\n",
      "print response.content[:1500]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<!DOCTYPE html>\r\n",
        "<!--[if lt IE 7]>      <html class=\"no-js lt-ie9 lt-ie8 lt-ie7\"> <![endif]-->\r\n",
        "<!--[if IE 7]>         <html class=\"no-js lt-ie9 lt-ie8\"> <![endif]-->\r\n",
        "<!--[if IE 8]>         <html class=\"no-js lt-ie9\"> <![endif]-->\r\n",
        "<!--[if IE 9]>         <html class=\"lt-ie10\"> <![endif]-->\r\n",
        "<!--[if gt IE 8]><!-->\r\n",
        "<html class=\"no-js\">\r\n",
        "<!--<![endif]-->\r\n",
        "<head>\r\n",
        "    <meta charset=\"utf-8\" />\r\n",
        "    <link rel=\"apple-touch-icon\" href=\"/apple-touch-icon.png\">\r\n",
        "    <link rel=\"apple-touch-icon\" sizes=\"72x72\" href=\"/apple-touch-icon-72x72-precomposed.png\">\r\n",
        "    <link rel=\"apple-touch-icon\" sizes=\"57x57\" href=\"/apple-touch-icon-57x57-precomposed.png\">\r\n",
        "    <link rel=\"apple-touch-icon\" sizes=\"114x114\" href=\"/apple-touch-icon-114x114-precomposed.png\">\r\n",
        "    <title>\r\n",
        "    Press Releases - The Florida Senate\r\n",
        "</title>\r\n",
        "    <link href=\"/Content/css/styles.css\" rel=\"stylesheet\" type=\"text/css\" media=\"screen\" />\r\n",
        "    <link href=\"/Content/css/print.css\" rel=\"stylesheet\" type=\"text/css\" media=\"print\" />\r\n",
        "    \r\n",
        "    <link rel=\"stylesheet\" type=\"text/css\" href=\"/Content/themes/base/jquery.ui.all.css\" />\r\n",
        "    <link href=\"/Areas/Media/css/media.css\" rel=\"stylesheet\"  type=\"text/css\" media=\"all\">\r\n",
        "\r\n",
        "\r\n",
        "    <!--[if lt IE 9]>\r\n",
        "            <script src=\"/Scripts/html5.js\"></script>\r\n",
        "        <![endif]-->\r\n",
        "    <!--[if (lt IE 9) & (!IEMobile)]>\r\n",
        "          <link rel=\"stylesheet\" href=\"/Content/css/ie.css\" />\r\n",
        "        <![endif]-->\r\n",
        "</head>\r\n",
        "<body>\r\n",
        "\r\n",
        "    <!-- Transparent image to track how many users have JavaSc\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we have obtained the HTML source from the website, and printed its first 1500 characters.  Recall that we want to obtain links to press releases, which will be contained in the \"href\" attribute in \"a\" tags in the body of the page.  One possibility would be to write a regular expression to return this, but most programming languages have HTML parsers that do the hard work for you.  Python has an excellent one called Beautiful Soup, whose documentation you can find on http://www.crummy.com/software/BeautifulSoup/.  Basically, an HTML parser breaks up HTML into its tag hierarchy, and allows you to quickly access the data you need."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup\n",
      "soup = BeautifulSoup(response.content)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, let's get all the links from the page we've just opened.  This corresponds to getting all \"a\" tags."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allA = soup.find_all('a')\n",
      "print len(allA)\n",
      "print allA[0]\n",
      "print allA[100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "195\n",
        "<a href=\"#menu\">Skip to Navigation</a>\n",
        "<a href=\"/Media/PressReleases/Show/2166\">MEMO: Legislation to Implement Amendment 1</a>\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This HTML document has 195 \"a\" tags.  When a full URL is not specificed, the link is to a page on the same domain.  So, for example, the first link is to https://www.flsenate.gov/#menu.  We are interested in links to press releases on the domain, which begin with the string '/Media/PressReleases/Show', so let's get just these."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_links = [link.get(\"href\") for link in allA if link.get(\"href\") != None]\n",
      "print all_links[0] # the text in the \"href\" attribute of the first \"a\" tag\n",
      "press_links = [link for link in all_links if link.startswith('/Media/PressReleases/Show')]\n",
      "print press_links[0] # the first press release link"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#menu\n",
        "/Media/PressReleases/Show/2176\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's obtain the HTML of the first press link just as before."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response2 = requests.get('https://www.flsenate.gov' + press_links[0])\n",
      "soup = BeautifulSoup(response2.content)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, a bit of inspection of this site will reveal that the text of the press release is embedded in a \"div\" tag with \"class\" attribute \"pr_content\".  We can use the parser to pick out this specific tag as follows."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "release = soup.find(\"div\", { 'class' : 'pr_content' })"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we want to get the individual paragraphs in the press release, we can extract the text from within the \"p\" tags as follows."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "paragraphs = [p.get_text() for p in release.find_all('p')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now suppose we want the title of the press release.  Again, a bit of inspection reveals this is contained in the \"h3\" tag within the \"div\" tag with \"id\" attribute value \"mediaContent\"."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "md = soup.find(\"div\", { 'id' : 'mediaContent' })\n",
      "title = md.find('h3').get_text()\n",
      "print title"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Legislation to Establish Policy for Amendment 1 Implementation\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Putting it All Together"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following code allows us to contruct the data we originally wanted."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "title = []\n",
      "text = []\n",
      "\n",
      "for link in press_links:\n",
      "\n",
      "\tresponse = requests.get('https://www.flsenate.gov' + link)\n",
      "\tsoup = BeautifulSoup(response.content)\n",
      "\n",
      "\tpr = soup.find(\"div\", { 'class' : 'pr_content' })\n",
      "\tparagraphs = [p.get_text() for p in pr.find_all('p')]\n",
      "\n",
      "\ttext = text + paragraphs\n",
      "\n",
      "\tmd = soup.find(\"div\", { 'id' : 'mediaContent' })\n",
      "\n",
      "\ttitle = title + [md.find('h3').get_text()]*len(paragraphs)\n",
      "\n",
      "\tprint(\"link %s complete\" % link)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "link /Media/PressReleases/Show/2176 complete\n",
        "link /Media/PressReleases/Show/2174 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2173 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2172 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2171 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2168 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2169 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2170 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2167 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2166 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2165 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2164 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2163 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2162 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2160 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2159 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2157 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2158 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2156 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2155 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2154 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2153 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2152 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2150 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "link /Media/PressReleases/Show/2151 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally we can input this into pandas in the usual way to have a database of text to analyze."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "data = pd.DataFrame({'title':title,'text':text})\n",
      "print data.shape[0] # number of total paragraphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "294\n"
       ]
      }
     ],
     "prompt_number": 10
    }
   ],
   "metadata": {}
  }
 ]
}